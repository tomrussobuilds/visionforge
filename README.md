# üîÆ VisionForge: Type-Safe Deep Learning Framework

<!-- Badges Section -->
<p align="center">
  <!-- CI/CD & Testing -->
  <a href="https://github.com/tomrussobuilds/visionforge/actions/workflows/ci.yml">
    <img src="https://github.com/tomrussobuilds/visionforge/actions/workflows/ci.yml/badge.svg" alt="CI/CD Pipeline">
  </a>
  <a href="https://docs.pytest.org/">
    <img src="https://img.shields.io/badge/tested%20with-pytest-blue?logo=pytest&logoColor=white" alt="Tested with pytest">
  </a>
  <a href="LICENSE">
    <img src="https://img.shields.io/badge/license-MIT-green" alt="License">
  </a>
</p>

<p align="center">
  <!-- Core Technologies -->
  <img src="https://img.shields.io/badge/python-3.10%2B-blue?logo=python&logoColor=white" alt="Python">
  <a href="https://pytorch.org/">
    <img src="https://img.shields.io/badge/PyTorch-2.0%2B-orange?logo=pytorch&logoColor=white" alt="PyTorch">
  </a>
  <a href="https://docs.pydantic.dev/">
    <img src="https://img.shields.io/badge/Pydantic-v2-e92063?logo=pydantic&logoColor=white" alt="Pydantic">
  </a>
  <a href="https://optuna.org/">
    <img src="https://img.shields.io/badge/Optuna-3.0%2B-00ADD8?logo=optuna&logoColor=white" alt="Optuna">
  </a>
</p>

<p align="center">
  <!-- Code Quality & Status -->
  <a href="https://github.com/psf/black">
    <img src="https://img.shields.io/badge/code%20style-black-000000.svg" alt="Black">
  </a>
  <img src="https://img.shields.io/badge/Architecture-Decoupled-blueviolet" alt="Architecture">
  <img src="https://img.shields.io/badge/status-Active-success" alt="Status">
  <a href="https://github.com/tomrussobuilds/visionforge/issues">
    <img src="https://img.shields.io/github/issues/tomrussobuilds/visionforge" alt="GitHub Issues">
  </a>
</p>

---

## üìå Table of Contents

- [üéØ Overview](#-overview)
- [üöÄ Quick Start](#-quick-start)
- [‚ú® Core Features](#-core-features)
- [üèó System Architecture](#-system-architecture)
- [üìä Experiment Management](#-experiment-management)
- [üß© Dependency Graph](#-dependency-graph)
- [üî¨ Technical Deep Dive](#-technical-deep-dive)
- [üìÅ Project Structure](#-project-structure)
- [üíª Usage Patterns](#-usage-patterns)
- [üéØ Hyperparameter Optimization](#-hyperparameter-optimization)
- [‚úÖ Environment Verification](#-environment-verification)
- [üê≥ Containerized Deployment](#-containerized-deployment)
- [üìä Configuration Reference](#-configuration-reference)
- [üîÑ Extending to New Datasets](#-extending-to-new-datasets)
- [üß™ Testing & Quality Assurance](#-testing--quality-assurance)
- [üìö Citation](#-citation)
- [üó∫ Development Roadmap](#-development-roadmap)

---

## üéØ Overview

**VisionForge** is a research-grade PyTorch training framework engineered for reproducible, scalable computer vision experiments. Originally designed for medical imaging (MedMNIST v2), it has evolved into a domain-agnostic platform supporting multi-resolution architectures (28√ó28 to 224√ó224+), automated hyperparameter optimization, and cluster-safe execution.

**Key Differentiators:**
- **Type-Safe Configuration Engine**: Pydantic V2-based declarative manifests eliminate runtime errors
- **Zero-Conflict Execution**: Kernel-level file locking (`fcntl`) prevents concurrent runs from corrupting shared resources
- **Intelligent Hyperparameter Search**: Optuna integration with TPE sampling and Median Pruning
- **Hardware-Agnostic**: Auto-detection and optimization for CPU/CUDA/MPS backends
- **Audit-Grade Traceability**: BLAKE2b-hashed run directories with full YAML snapshots


**Representative Benchmarks** (RTX 5070):

| Task | Architecture | Resolution | Trials | Time | Notes |
|------|-------------|-----------|--------|------|-------|
| **Training** | ResNet-18 | 28√ó28 | - | ~5 min (60 epochs) | BloodMNIST, GPU |
| **Training** | ResNet-18 | 28√ó28 | - | ~2.5h (60 epochs) | BloodMNIST, CPU (16 cores) |
| **Optimization** | EfficientNet-B0 | 224√ó224 | 3 | ~1.5h | OrganCMNIST, **early stopped** at AUC‚â•0.9999 |
| **Single Trial** | EfficientNet-B0 | 224√ó224 | 1 | ~29 min (15 epochs) | OrganCMNIST, batch size 8 |

>[!Note]
>**Timing Variance**: GPU training times are highly dependent on early stopping criteria and dataset complexity.
>- BloodMNIST 28√ó28 completes in ~5 minutes on RTX 5070
>- Larger datasets and higher resolutions require hours without early stopping
>- Optimization may finish in 1-3 hours if target metrics are reached early (e.g., AUC ‚â• 0.9999)

---

## üöÄ Quick Start

```bash
# 1. Clone and setup environment
git clone https://github.com/tomrussobuilds/visionforge.git
cd visionforge
pip install -r requirements.txt

# 2. Run a quick verification (1-epoch sanity check, ~30 seconds)
python -m tests.smoke_test

# 3. Train with optimized recipe 
python main.py --config recipes/config_resnet_18_adapted.yaml

# 4. Launch hyperparameter optimization (50 trials, time varies with early stopping)
python optimize.py --config recipes/optuna_resnet_18_adapted.yaml

# 5. View optimization results
firefox outputs/*/figures/param_importances.html

# 6. Deploy best configuration
python main.py --config outputs/*/reports/best_config.yaml
```

---

## ‚ú® Core Features

### üîí Enterprise-Grade Execution Safety

**Tiered Configuration Engine (SSOT)**  
Built on Pydantic V2, the configuration system acts as a **Single Source of Truth**, transforming raw inputs (CLI/YAML) into an immutable, type-safe execution blueprint:

- **Late-Binding Metadata Injection**: Dataset specifications (normalization constants, class mappings) are resolved from a centralized registry at instantiation time
- **Cross-Domain Validation**: Post-construction logic guards prevent unstable states (e.g., enforcing RGB input for pretrained weights, validating AMP compatibility)
- **Path Portability**: Automatic serialization converts absolute paths to environment-agnostic anchors for cross-platform reproducibility

**Infrastructure Guard Layer**  
An independent `InfrastructureManager` bridges declarative configs with physical hardware:

- **Mutual Exclusion via `flock`**: Kernel-level advisory locking ensures only one training instance per workspace (prevents VRAM race conditions)
- **Process Sanitization**: `psutil` wrapper identifies and terminates ghost Python processes
- **HPC-Aware Safety**: Auto-detects cluster schedulers (SLURM/PBS/LSF) and suspends aggressive process cleanup to preserve multi-user stability

**Deterministic Run Isolation**  
Every execution generates a unique workspace using:
```
outputs/YYYYMMDD_DS_MODEL_HASH6/
```
Where `HASH6` is a BLAKE2b cryptographic digest (3-byte, deterministic) computed from the training configuration. Even minor hyperparameter variations produce isolated directories, preventing resource overlap and ensuring auditability.

### üî¨ Reproducibility Architecture

**Dual-Layer Reproducibility Strategy:**
1. **Standard Mode**: Global seeding (Seed 42) with performance-optimized algorithms
2. **Strict Mode**: Bit-perfect reproducibility via:
   - `torch.use_deterministic_algorithms(True)`
   - `worker_init_fn` for multi-process RNG synchronization
   - Auto-scaling to `num_workers=0` when determinism is critical

**Data Integrity Validation:**
- MD5 checksum verification for dataset downloads
- `validate_npz_keys` structural integrity checks before memory allocation

### ‚ö° Performance Optimization

**Hybrid RAM Management:**
- **Small Datasets** (<50K samples): Full RAM caching for maximum throughput
- **Large Datasets** (>100K samples): Indexed slicing to prevent OOM errors

**Dynamic Path Anchoring:**
- "Search-up" logic locates project root via markers (`.git`, `README.md`)
- Ensures absolute path stability regardless of invocation directory

**Graceful Logger Reconfiguration:**
- Initial logs route to `STDOUT` for immediate feedback
- Hot-swap to timestamped file handler post-initialization without trace loss

### üéØ Intelligent Hyperparameter Search

**Optuna Integration Features:**
- **TPE Sampling**: Tree-structured Parzen Estimator for efficient search space exploration
- **Median Pruning**: Early stopping of underperforming trials (30-50% time savings)
- **Persistent Studies**: SQLite storage enables resume-from-checkpoint
- **Type-Safe Constraints**: All search spaces respect Pydantic validation bounds
- **Auto-Visualization**: Parameter importance plots, optimization history, parallel coordinates

---

## üèó System Architecture

The framework implements **Separation of Concerns (SoC)** with five core layers:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      RootOrchestrator                           ‚îÇ
‚îÇ              (Lifecycle Manager & Context)                      ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Responsibilities:                                              ‚îÇ
‚îÇ  ‚Ä¢ Phase 1-7 initialization sequence                            ‚îÇ
‚îÇ  ‚Ä¢ Resource acquisition & cleanup (Context Manager)             ‚îÇ
‚îÇ  ‚Ä¢ Device resolution & caching                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ                         ‚îÇ
             ‚îÇ uses                    ‚îÇ uses
             ‚îÇ                         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                   ‚îÇ     ‚îÇ                        ‚îÇ
    ‚îÇ  Config Engine    ‚îÇ     ‚îÇ  InfrastructureManager ‚îÇ
    ‚îÇ  (Pydantic V2)    ‚îÇ     ‚îÇ  (flock/psutil)        ‚îÇ
    ‚îÇ                   ‚îÇ     ‚îÇ                        ‚îÇ
    ‚îÇ  ‚Ä¢ Type safety    ‚îÇ     ‚îÇ  ‚Ä¢ Process cleanup     ‚îÇ
    ‚îÇ  ‚Ä¢ Validation     ‚îÇ     ‚îÇ  ‚Ä¢ Kernel locks        ‚îÇ
    ‚îÇ  ‚Ä¢ Metadata       ‚îÇ     ‚îÇ  ‚Ä¢ HPC detection       ‚îÇ
    ‚îÇ    injection      ‚îÇ     ‚îÇ                        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚îÇ provides config to
             ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                                                        ‚îÇ
    ‚îÇ              Execution Pipeline                        ‚îÇ
    ‚îÇ                                                        ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
    ‚îÇ  ‚îÇ   Data   ‚îÇ  ‚îÇ  Model   ‚îÇ  ‚îÇ Trainer  ‚îÇ              ‚îÇ
    ‚îÇ  ‚îÇ Handler  ‚îÇ‚Üí ‚îÇ Factory  ‚îÇ‚Üí ‚îÇ  Engine  ‚îÇ              ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
    ‚îÇ                                   ‚îÇ                    ‚îÇ
    ‚îÇ                             ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
    ‚îÇ                             ‚îÇ Evaluation ‚îÇ             ‚îÇ
    ‚îÇ                             ‚îÇ  Pipeline  ‚îÇ             ‚îÇ
    ‚îÇ                             ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
    ‚îÇ                                                        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚îÇ alternative path
                                 ‚îÇ
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ  Optimization Engine  ‚îÇ
                        ‚îÇ      (Optuna)         ‚îÇ
                        ‚îÇ                       ‚îÇ
                        ‚îÇ  ‚Ä¢ Study management   ‚îÇ
                        ‚îÇ  ‚Ä¢ Trial execution    ‚îÇ
                        ‚îÇ  ‚Ä¢ Pruning logic      ‚îÇ
                        ‚îÇ  ‚Ä¢ Visualization      ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key Design Principles:**

1. Orchestrator owns both Config and InfrastructureManager
2. Config is the SSOT - all modules receive it as dependency
3. InfrastructureManager is stateless utility for OS-level operations
4. Execution pipeline is linear: Data ‚Üí Model ‚Üí Training ‚Üí Eval
5. Optimization wraps the entire pipeline for each trial

---

## üìä Experiment Management

Every run generates a complete artifact suite for total traceability:

**Artifact Structure:**
```
outputs/20260116_organcmnist_optuna_a3f7c2/
‚îú‚îÄ‚îÄ figures/
‚îÇ   ‚îú‚îÄ‚îÄ param_importances.html      # Interactive importance plot
‚îÇ   ‚îú‚îÄ‚îÄ optimization_history.html   # Trial progression
‚îÇ   ‚îî‚îÄ‚îÄ parallel_coordinates.html   # Hyperparameter relationships
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ best_config.yaml            # Optimized configuration
‚îÇ   ‚îú‚îÄ‚îÄ study_summary.json          # All trials metadata
‚îÇ   ‚îî‚îÄ‚îÄ top_10_trials.xlsx          # Best configurations
‚îî‚îÄ‚îÄ database/
    ‚îî‚îÄ‚îÄ study.db                    # SQLite storage for resumption
```

> [!IMPORTANT]
> ### üìÇ [View Sample Artifacts](./docs/artifacts)
> Explore Excel reports, YAML configs, and diagnostic plots from real experiments.

---

## üß© Dependency Graph

<p align="center">
<img src="docs/framework_map.svg?v=4" width="900" alt="System Dependency Graph">
</p>

> *Generated via `pydeps`. Highlights the centralized Config hub and modular architecture.*

<details>
<summary>üõ†Ô∏è Regenerate Dependency Graph</summary>

```bash
pydeps orchard \
    --cluster \
    --max-bacon=0 \
    --max-module-depth=4 \
    --only orchard \
    --noshow \
    -T svg \
    -o docs/framework_map.svg
```

**Requirements:** `pydeps` + Graphviz (`sudo apt install graphviz` or `brew install graphviz`)

</details>

---

## üî¨ Technical Deep Dive

### Architecture Adaptation

Standard ResNet-18 is optimized for 224√ó224 ImageNet inputs. Direct application to 28√ó28 domains causes catastrophic information loss. Our adaptation strategy:

| Layer | Standard ResNet-18 | VisionForge Adapted | Rationale |
|-------|-------------------|---------------------|-----------|
| **Input Conv** | 7√ó7, stride=2, pad=3 | **3√ó3, stride=1, pad=1** | Preserve spatial resolution |
| **Max Pooling** | 3√ó3, stride=2 | **Identity (bypassed)** | Prevent 75% feature loss |
| **Stage 1 Input** | 56√ó56 (from 224) | **28√ó28 (from 28)** | Native resolution entry |

**Key Modifications:**
1. **Stem Redesign**: Replacing large-receptive-field convolution avoids immediate downsampling
2. **Pooling Removal**: MaxPool bypass maintains full spatial fidelity into residual stages
3. **Bicubic Weight Transfer**: Pretrained 7√ó7 weights are spatially interpolated to 3√ó3 geometry

### Mathematical Weight Transfer

To retain ImageNet-learned feature detectors, we apply bicubic interpolation:

**Source Tensor:**

```math
W_{\text{src}} \in \mathbb{R}^{C_{\text{out}} \times C_{\text{in}} \times 7 \times 7}
```

**Transformation:**

```math
W_{\text{dest}} = \mathcal{I}_{\text{bicubic}}(W_{\text{src}}, \text{size}=(3, 3))
```

**Result:** A 3√ó3 kernel preserving edge-detection patterns optimized for compact receptive fields, enabling faster convergence than random initialization.

### Training Regularization

**MixUp Augmentation** synthesizes training samples via convex combinations:

```math
\tilde{x} = \lambda x_i + (1 - \lambda) x_j \quad \text{where} \quad \lambda \sim \text{Beta}(\alpha, \alpha)
```

```math
\tilde{y} = \lambda y_i + (1 - \lambda) y_j
```

This prevents overfitting on small-scale textures and improves generalization.


---

## üìÅ Project Structure

```
visionforge/
‚îú‚îÄ‚îÄ main.py                         # Training entry point
‚îú‚îÄ‚îÄ optimize.py                     # Hyperparameter search entry point
‚îú‚îÄ‚îÄ Dockerfile                      # Multi-stage reproducible build
‚îú‚îÄ‚îÄ requirements.txt                # Pinned dependencies
‚îú‚îÄ‚îÄ recipes/                        # YAML configuration presets
‚îÇ   ‚îú‚îÄ‚îÄ config_resnet_18_adapted.yaml
‚îÇ   ‚îú‚îÄ‚îÄ config_efficientnet_b0.yaml
‚îÇ   ‚îú‚îÄ‚îÄ optuna_resnet_18_adapted.yaml
‚îÇ   ‚îî‚îÄ‚îÄ optuna_efficientnet_b0.yaml
‚îú‚îÄ‚îÄ tests/                          # Diagnostic utilities
‚îÇ   ‚îú‚îÄ‚îÄ smoke_test.py               # 1-epoch E2E verification (~30s)
‚îÇ   ‚îú‚îÄ‚îÄ health_check.py             # Dataset integrity validation
‚îÇ   ‚îî‚îÄ‚îÄ test_engine.py              # Unit test suite
‚îú‚îÄ‚îÄ tests/                          # Test suite (pytest)
‚îÇ   ‚îú‚îÄ‚îÄ test_dataset.py             # Dataset config tests
‚îÇ   ‚îú‚îÄ‚îÄ test_engine.py              # Config engine tests
‚îÇ   ‚îî‚îÄ‚îÄ conftest.py                 # Shared fixtures
‚îú‚îÄ‚îÄ orchard/                        # Core framework package
‚îÇ   ‚îú‚îÄ‚îÄ core/                       # Framework nucleus
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/                 # Pydantic schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ environment/            # Hardware abstraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ io/                     # Serialization utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger/                 # Telemetry system
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metadata/               # Dataset registry
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ paths/                  # Path management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cli.py                  # Argument parser
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ orchestrator.py         # Lifecycle coordinator
‚îÇ   ‚îú‚îÄ‚îÄ data_handler/               # Loading strategies
‚îÇ   ‚îú‚îÄ‚îÄ models/                     # Architecture factory
‚îÇ   ‚îú‚îÄ‚îÄ trainer/                    # Training loop
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/                 # Metrics and visualization
‚îÇ   ‚îî‚îÄ‚îÄ optimization/               # Optuna integration
‚îÇ       ‚îú‚îÄ‚îÄ objective.py            # Trial execution logic
‚îÇ       ‚îú‚îÄ‚îÄ orchestrator.py         # Study management
‚îÇ       ‚îî‚îÄ‚îÄ search_spaces.py        # Hyperparameter distributions
‚îî‚îÄ‚îÄ outputs/                        # Isolated run workspaces
```

---

## üíª Usage Patterns

### Configuration-Driven Execution

**Recommended Method:** YAML recipes ensure full reproducibility and version control.

```bash
# Verify environment (~30 seconds)
python -m tests.smoke_test

# Train with preset (ResNet-18, 28√ó28, ~5 min on GPU)
python main.py --config recipes/config_resnet_18_adapted.yaml

# Train with preset (EfficientNet-B0, 224√ó224, ~30 min per trial)
python main.py --config recipes/config_efficientnet_b0.yaml
```

### CLI Overrides

For rapid experimentation (not recommended for production):

```bash
# Quick test on different dataset
python main.py --dataset dermamnist --epochs 10 --batch_size 64

# Custom learning rate schedule
python main.py --lr 0.001 --min_lr 1e-7 --epochs 100

# Disable augmentations
python main.py --mixup_alpha 0 --no_tta
```

> [!WARNING]
> **Configuration Precedence Order:**
> 1. **YAML file** (highest priority - if `--config` is provided)
> 2. **CLI arguments** (only used when no `--config` specified)
> 3. **Defaults** (from Pydantic field definitions)
>
> **When `--config` is provided, YAML values override CLI arguments.** This prevents configuration drift but means CLI flags are ignored. For reproducible research, always use YAML recipes.

---

## üéØ Hyperparameter Optimization

### Quick Start

```bash
# Install Optuna (if not already present)
pip install optuna plotly

# Run optimization with preset (28√ó28, 50 trials, time varies)
python optimize.py --config recipes/optuna_resnet_18_adapted.yaml

# Run optimization with preset (224√ó224, 20 trials, time varies)
python optimize.py --config recipes/optuna_efficientnet_b0.yaml

# Custom search (20 trials, 10 epochs each)
python optimize.py --dataset pathmnist \
    --n_trials 20 \
    --epochs 10 \
    --search_space_preset quick

# Resume interrupted study
python optimize.py --config recipes/optuna_resnet_18_adapted.yaml \
    --load_if_exists true
```

### Search Space Coverage

**Full Space** (13 parameters):
- **Optimization**: `learning_rate`, `weight_decay`, `momentum`, `min_lr`
- **Regularization**: `mixup_alpha`, `label_smoothing`, `dropout`
- **Scheduling**: `cosine_fraction`, `scheduler_patience`
- **Augmentation**: `rotation_angle`, `jitter_val`, `min_scale`
- **Batch Size**: Resolution-aware categorical choices
  - 28√ó28: [16, 32, 48, 64]
  - 224√ó224: [8, 12, 16] (OOM-safe for 8GB VRAM)

**Quick Space** (4 parameters):
- `learning_rate`, `weight_decay`, `batch_size`, `dropout`

### Optimization Workflow

```bash
# Phase 1: Rapid exploration (20 trials, 10 epochs, ~2-4h depending on dataset)
python optimize.py --config recipes/optuna_resnet_18_adapted.yaml \
    --n_trials 20 --epochs 10

# Phase 2: Comprehensive search (50 trials, 15 epochs, time varies significantly)
python optimize.py --config recipes/optuna_resnet_18_adapted.yaml

# Phase 3: Final training with best config (60 epochs)
python main.py --config outputs/*/reports/best_config.yaml --epochs 60
```

### Artifacts Generated

```
outputs/20250116_bloodmnist_optuna_a3f7c2/
‚îú‚îÄ‚îÄ figures/
‚îÇ   ‚îú‚îÄ‚îÄ param_importances.html      # Interactive importance plot
‚îÇ   ‚îú‚îÄ‚îÄ optimization_history.html   # Trial progression
‚îÇ   ‚îî‚îÄ‚îÄ parallel_coordinates.html   # Hyperparameter relationships
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ best_config.yaml            # Optimized configuration
‚îÇ   ‚îú‚îÄ‚îÄ study_summary.json          # All trials metadata
‚îÇ   ‚îî‚îÄ‚îÄ top_10_trials.xlsx          # Best configurations
‚îî‚îÄ‚îÄ database/
    ‚îî‚îÄ‚îÄ study.db                    # SQLite storage for resumption
```

### Customization

Edit search spaces in `orchard/optimization/search_spaces.py`:

```python
class CustomSearchSpace:
    @staticmethod
    def get_optimization_space() -> Dict[str, Callable]:
        return {
            "learning_rate": lambda trial: trial.suggest_float(
                "learning_rate", 1e-4, 1e-2, log=True
            ),
            "weight_decay": lambda trial: trial.suggest_float(
                "weight_decay", 1e-5, 1e-3, log=True
            ),
        }
```

---

## ‚úÖ Environment Verification

**Smoke Test** (1-epoch sanity check):
```bash
python -m tests.smoke_test
```

**Output:** Validates full pipeline in <30 seconds:
- Dataset loading and preprocessing
- Model instantiation and weight transfer
- Training loop execution
- Evaluation metrics computation
- Excel/PNG artifact generation

**Health Check** (dataset integrity):
```bash
python -m tests.health_check --dataset bloodmnist
```

**Output:** Verifies:
- MD5 checksum matching
- NPZ key structure (`train_images`, `train_labels`, `val_images`, etc.)
- Sample count validation

---

## üê≥ Containerized Deployment

### Build Image

```bash
docker build -t visionforge:latest .
```

### Execution Modes

**Standard Mode** (Performance Optimized):
```bash
docker run -it --rm \
  --gpus all \
  -u $(id -u):$(id -g) \
  -e TORCH_HOME=/tmp/torch_cache \
  -e MPLCONFIGDIR=/tmp/matplotlib_cache \
  -v $(pwd)/dataset:/app/dataset \
  -v $(pwd)/outputs:/app/outputs \
  visionforge:latest \
  --config recipes/config_resnet_18_adapted.yaml
```

**Strict Reproducibility Mode** (Bit-Perfect Determinism):
```bash
docker run -it --rm \
  --gpus all \
  -u $(id -u):$(id -g) \
  -e IN_DOCKER=TRUE \
  -e DOCKER_REPRODUCIBILITY_MODE=TRUE \
  -e TORCH_HOME=/tmp/torch_cache \
  -e MPLCONFIGDIR=/tmp/matplotlib_cache \
  -e PYTHONHASHSEED=42 \
  -e CUBLAS_WORKSPACE_CONFIG=:4096:8 \
  -v $(pwd)/dataset:/app/dataset \
  -v $(pwd)/outputs:/app/outputs \
  visionforge:latest \
  --config recipes/config_resnet_18_adapted.yaml \
  --reproducible
```

> [!NOTE]
> - `TORCH_HOME` and `MPLCONFIGDIR` prevent permission errors in containerized environments
> - `CUBLAS_WORKSPACE_CONFIG` is required for CUDA determinism
> - `--gpus all` requires NVIDIA Container Toolkit

---

## üìä Configuration Reference

### Core Parameters

| Parameter | Type | Default | Range | Description |
|-----------|------|---------|-------|-------------|
| `epochs` | int | 60 | [1, 1000] | Training epochs |
| `batch_size` | int | 128 | [1, 2048] | Samples per batch |
| `learning_rate` | float | 0.008 | (1e-8, 1.0) | Initial SGD learning rate |
| `min_lr` | float | 1e-6 | (0, lr) | Minimum LR for scheduler |
| `weight_decay` | float | 5e-4 | [0, 0.2] | L2 regularization |
| `momentum` | float | 0.9 | [0, 1) | SGD momentum |
| `mixup_alpha` | float | 0.002 | [0, 1] | MixUp strength (0=disabled) |
| `label_smoothing` | float | 0.0 | [0, 0.3] | Label smoothing factor |
| `dropout` | float | 0.0 | [0, 0.9] | Dropout probability |
| `seed` | int | 42 | - | Global random seed |
| `reproducible` | bool | False | - | Enable strict determinism |

### Augmentation Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `hflip` | float | 0.5 | Horizontal flip probability |
| `rotation_angle` | int | 10 | Max rotation degrees |
| `jitter_val` | float | 0.2 | ColorJitter intensity |
| `min_scale` | float | 0.95 | Minimum RandomResizedCrop scale |
| `no_tta` | bool | False | Disable test-time augmentation |

### Model Parameters

| Parameter | Type | Default | Options |
|-----------|------|---------|---------|
| `model_name` | str | "resnet_18_adapted" | `resnet_18_adapted`, `efficientnet_b0` |
| `pretrained` | bool | True | Use ImageNet weights |
| `force_rgb` | bool | True | Convert grayscale to 3-channel |
| `resolution` | int | 28 | [28, 224] |

### Dataset Parameters

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `dataset` | str | "bloodmnist" | MedMNIST identifier |
| `data_root` | Path | `./dataset` | Dataset directory |
| `max_samples` | int | None | Cap training samples (debugging) |
| `use_weighted_sampler` | bool | True | Balance class distribution |

---

## üîÑ Extending to New Datasets

The framework is designed for zero-code dataset integration via the registry system:

### 1. Add Dataset Metadata

Edit `orchard/core/metadata/medmnist_v2_28x28.py`:

```python
DATASET_REGISTRY = {
    "custom_dataset": DatasetMetadata(
        name="custom_dataset",
        num_classes=10,
        in_channels=3,
        mean=(0.5, 0.5, 0.5),
        std=(0.25, 0.25, 0.25),
        native_resolution=28,
        class_names=["class0", "class1", ...],
        url="https://example.com/dataset.npz",
        md5="abc123..."
    ),
}
```

### 2. Train Immediately

```bash
python main.py --dataset custom_dataset --epochs 30
```

No code changes required‚Äîthe configuration engine automatically resolves metadata.

---

## üß™ Testing & Quality Assurance

### Test Suite

VisionForge includes a comprehensive test suite with >90 tests covering:

```bash
# Run full test suite
pytest tests/ -v

# Run with coverage report
pytest tests/ --cov=orchard --cov-report=html

# Run specific test categories
pytest tests/ -m unit          # Unit tests only
pytest tests/ -m integration   # Integration tests only

# Run parallel tests (faster)
pytest tests/ -n auto
```

### Test Categories

- **Unit Tests** (90+ tests): Config validation, metadata injection, type safety
- **Integration Tests**: End-to-end pipeline validation, YAML hydration
- **Smoke Tests**: 1-epoch sanity checks (~30 seconds)
- **Health Checks**: Dataset integrity validation

### Continuous Integration

GitHub Actions automatically run on every push:

- ‚úÖ Code quality checks (Black, isort, Flake8)
- ‚úÖ Unit tests across Python 3.10, 3.11, 3.12
- ‚úÖ Smoke tests (E2E validation)
- ‚úÖ Dataset health checks
- ‚úÖ Security scanning (Bandit, Safety)
- ‚úÖ Code coverage reporting (Codecov)

View the latest build status: [![CI/CD](https://github.com/tomrussobuilds/visionforge/actions/workflows/ci.yml/badge.svg)](https://github.com/tomrussobuilds/visionforge/actions/workflows/ci.yml)

---

## üìö Citation

```bibtex
@software{visionforge2025,
  author = {Tommaso Russo},
  title  = {VisionForge: Type-Safe Deep Learning Framework},
  year   = {2025},
  url    = {https://github.com/tomrussobuilds/visionforge},
  note   = {PyTorch framework with Pydantic configuration and Optuna optimization}
}
```

---

## üó∫ Development Roadmap

### ‚úÖ Phase 1: Foundation (Completed)
- Architecture adaptation (3√ó3 stem, MaxPool removal)
- Pydantic-based configuration engine
- Infrastructure safety (flock, process management)

### ‚úÖ Phase 2: Automation (Completed)
- YAML-driven execution model
- Optuna hyperparameter optimization
- Multi-resolution support (28√ó28, 224√ó224)
- Comprehensive test suite (>90 tests)
- CI/CD pipeline with GitHub Actions

### üîÑ Phase 3: Modern Architectures (Current)
- Vision Transformer (ViT) integration
- EfficientNet-V2 support
- ConvNeXt architecture addition
- Attention mechanism analysis

### üîÆ Phase 4: Domain Transcendence (Planned)
- Abstract dataset registry for non-medical domains
- Multi-modal hooks (detection, segmentation)
- Distributed training support (DDP, FSDP)
- TorchScript/ONNX export pipeline
- Benchmark suite for architecture comparison

---

## üìÑ License

MIT License - See [LICENSE](LICENSE) for details.

## ü§ù Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass: `pytest tests/ -v`
5. Submit a pull request

## üìß Contact

For questions or collaboration: [GitHub Issues](https://github.com/tomrussobuilds/visionforge/issues)

---

<p align="center">
<strong>Built with ‚ù§Ô∏è for reproducible research</strong>
</p>