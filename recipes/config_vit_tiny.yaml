# ==============================================================================
# FILE: recipes/config_vit_tiny.yaml
# Vision Transformer Tiny Training Configuration (224x224)
# ==============================================================================
# Usage: python forge.py --config recipes/config_vit_tiny.yaml
# Estimated Time: ~25-35 min GPU (30 epochs, RTX 5070, GPU required)
# Memory Usage: ~3.5GB VRAM with AMP
# Architecture: ViT-Tiny (5M parameters, patch-based attention)

dataset:
  name: "organcmnist"
  data_root: ./dataset
  resolution: 224
  force_rgb: true
  use_weighted_sampler: true
  max_samples: null

architecture:
  name: "vit_tiny"
  pretrained: true
  weight_variant: "vit_tiny_patch16_224.augreg_in21k_ft_in1k"  # ImageNet-21k â†’ 1k
  dropout: 0.1

training:
  seed: 42

  # Optimization (ViT benefits from lower LR than CNNs)
  batch_size: 16                # Conservative for 224x224
  learning_rate: 0.0003         # Lower than CNN defaults
  weight_decay: 0.0001          # Light regularization
  momentum: 0.9
  min_lr: 1e-7
  
  # Regularization
  mixup_alpha: 0.2              # Moderate mixup for ViT
  label_smoothing: 0.1
  
  # Training loop
  epochs: 30
  patience: 10
  grad_clip: 1.0
  mixup_epochs: 0               # 0 = apply throughout training
  
  # Scheduler
  scheduler_type: "cosine"
  cosine_fraction: 0.8
  scheduler_patience: 5
  scheduler_factor: 0.1
  step_size: 20
  
  # Performance
  use_amp: true                 # REQUIRED for 224x224
  use_tta: true
  criterion_type: "cross_entropy"
  weighted_loss: false
  focal_gamma: 2.0              # Only used if criterion_type: "focal"

augmentation:
  hflip: 0.5
  rotation_angle: 10
  jitter_val: 0.2
  min_scale: 0.95
  tta_translate: 0.5
  tta_scale: 1.02
  tta_blur_sigma: 0.1

hardware:
  device: "auto"

telemetry:
  output_dir: ./outputs
  log_level: "INFO"
  log_interval: 50

evaluation:
  batch_size: 32
  n_samples: 12
  fig_dpi: 200
  cmap_confusion: Blues
  plot_style: seaborn-v0_8-muted
  grid_cols: 4
  fig_size_predictions: [12, 8]
  report_format: xlsx
  save_confusion_matrix: true
  save_predictions_grid: true

tracking:
  enabled: true
  experiment_name: "visionforge"

export:
  format: onnx
  opset_version: 18
  validate_export: true